{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvDieaRFh0Hx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao3pEu8dh0H5"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels_img, features_d):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(                  ## 64x64\n",
        "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),   ## 32x32\n",
        "            nn.LeakyReLU(0.02),\n",
        "            self._block(features_d, features_d*2, kernel_size=4, stride=2, padding=1),     ## 16x16\n",
        "            self._block(features_d*2, features_d*4, kernel_size=4, stride=2, padding=1),   ## 8x8\n",
        "            self._block(features_d*4, features_d*8, kernel_size=4, stride=2, padding=1),   ## 4x4\n",
        "            nn.Conv2d(features_d*8, 1, kernel_size=4, stride=2, padding=0),                ## 1x1\n",
        "            # nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \\\n",
        "                kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.02)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.disc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-BCeF6mh0H6"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, channels_img, feature_g):\n",
        "        super(Generator, self).__init__()\n",
        "        self.gen = nn.Sequential(                            ## 1x1\n",
        "            self._block(z_dim, feature_g*16, 4, 1, 0),       ## 4x4\n",
        "            self._block(feature_g*16, feature_g*8, 4, 2, 1), ## 8x8\n",
        "            self._block(feature_g*8, feature_g*4, 4, 2, 1),  ## 16x16\n",
        "            self._block(feature_g*4, feature_g*2, 4, 2, 1),  ## 32x32\n",
        "            nn.ConvTranspose2d(in_channels=feature_g*2, out_channels=channels_img, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, \\\n",
        "                kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gen(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW9lnRgch0H7",
        "outputId": "6ee94cac-ad9e-423d-9b65-14bf8e24f5a8"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "\n",
        "def test():\n",
        "    N, in_channels, H, W = 8, 3, 64, 64\n",
        "    z_dim = 100\n",
        "    x = torch.randn((N, in_channels, H, W))\n",
        "    disc = Discriminator(in_channels, 8)\n",
        "    initialize_weights(disc)\n",
        "    assert disc(x).shape == (N, 1, 1, 1)\n",
        "    gen = Generator(z_dim, in_channels, 8)\n",
        "    initialize_weights(gen)\n",
        "    z = torch.randn((N, z_dim, 1, 1))\n",
        "    assert gen(z).shape == (N, in_channels, H, W)\n",
        "    print('SUCCESS')\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PIpNv-Ah0H7",
        "outputId": "60488c13-8a87-4a65-8846-bfddfe3e4bc5"
      },
      "outputs": [],
      "source": [
        "## Hyperparameters\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "LEARNING_RATE = 5e-5\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 64\n",
        "CHANNELS_IMG = 1\n",
        "Z_DIM = 128\n",
        "NUM_EPOCHS = 5\n",
        "FEATURES_CRITIC = 64\n",
        "FEATURES_GEN = 64\n",
        "CRITIC_ITERATIONS = 5\n",
        "WEIGHT_CLIP = 0.01\n",
        "\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aEIKV9qh0H8"
      },
      "outputs": [],
      "source": [
        "transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(IMAGE_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)])\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Q_LymbWh0H8"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms, download=True)\n",
        "loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xdiisxBh0H9"
      },
      "outputs": [],
      "source": [
        "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(DEVICE)\n",
        "critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(DEVICE)\n",
        "initialize_weights(gen)\n",
        "initialize_weights(critic)\n",
        "\n",
        "# initializate optimizer\n",
        "opt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\n",
        "opt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BxHbMeNLh0H9",
        "outputId": "3bfa4302-c4e3-4615-8a16-498279e0f8c0"
      },
      "outputs": [],
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    gen.train()\n",
        "    critic.train()\n",
        "    \n",
        "    for batch_idx, (real, _) in enumerate(loader):\n",
        "        real = real.to(DEVICE)\n",
        "        ## Training Critic\n",
        "        for _ in range(CRITIC_ITERATIONS):\n",
        "            noise = torch.randn((BATCH_SIZE, Z_DIM, 1, 1)).to(DEVICE)\n",
        "            fake = gen(noise)\n",
        "            critic_real = critic(real).reshape(-1)\n",
        "            critic_fake = critic(fake).reshape(-1)\n",
        "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
        "            critic.zero_grad()\n",
        "            loss_critic.backward(retain_graph=True)\n",
        "            opt_critic.step()\n",
        "                \n",
        "        noise = torch.randn((BATCH_SIZE, Z_DIM, 1, 1)).to(DEVICE)\n",
        "        fake = gen(noise)\n",
        "            \n",
        "        ## Train Generator\n",
        "        output = critic(fake).reshape(-1)\n",
        "        loss_gen = -torch.mean(output)\n",
        "        gen.zero_grad()\n",
        "        loss_gen.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        if batch_idx%100 == 0:\n",
        "            with torch.no_grad():\n",
        "                print(f'epoch - {epoch}/{NUM_EPOCHS} || {batch_idx}/{len(loader)} || loss D: {loss_critic} || loss G: {loss_gen}')\n",
        "                gen_fake_img = gen(fixed_noise)\n",
        "                img_grid_fake = torchvision.utils.make_grid(\n",
        "                    gen_fake_img[:32], normalize=True\n",
        "                ).cpu()\n",
        "                plt.imshow(img_grid_fake.permute(1, 2, 0))\n",
        "                plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
